{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KesP3WrhTFrz"
      },
      "source": [
        "#Import Packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import sys,traceback"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r4R_KLHTG8O"
      },
      "source": [
        "'''Function to load the dataset'''\n",
        "def data_init(data_filepath):\n",
        "    try:\n",
        "        hr = pd.read_csv(data_filepath,low_memory= False)\n",
        "\n",
        "        col_list = list(hr)\n",
        "\n",
        "        print(\"Loaded successfully.\")\n",
        "    \n",
        "        return hr\n",
        "    except:\n",
        "        print(\"File Could not be loaded\")\n",
        "        print(\"Check your file or filepathname\")\n",
        "        return False"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "hso_p4guTQE7",
        "outputId": "ea44f59c-100b-47a1-a7cb-3caaa2ef84cc"
      },
      "source": [
        "'''User interacive way to access the dataset'''\n",
        "c = 1\n",
        "while (c!=0):\n",
        "    data_filepath = str(input(\"Enter data filepath:\"))\n",
        "    if os.path.isfile(data_filepath) :\n",
        "        hr_data = data_init(data_filepath)\n",
        "    else:\n",
        "        '''Add double slash in filepath and try again!'''\n",
        "        data_filepath = re.escape(data_filepath)\n",
        "        hr_data = data_init(data_filepath)\n",
        "    if type(hr_data) != str: c = 0\n",
        "    else: print (\"Check if file exists in the filepath and Let's try again ! \\n\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-f0861a33ac74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter data filepath:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_filepath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mhr_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcUL9C1ZTTcA"
      },
      "source": [
        "#Import Data\n",
        "hr = hr_data\n",
        "col_names = hr.columns.tolist()\n",
        "print(\"Column names:\")\n",
        "print(col_names)\n",
        "\n",
        "print(\"\\nSample data:\")\n",
        "hr.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdbNPYgUUuoQ"
      },
      "source": [
        "#Rename 'sales' column to department \n",
        "hr=hr.rename(columns = {'sales':'department'})\n",
        "#Display data type for each column\n",
        "hr.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-zeoTQdUu2Q"
      },
      "source": [
        "#Check for Missing Values\n",
        "hr.isnull().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_DDGxxAUu9P"
      },
      "source": [
        "#Dimensions of our dataset\n",
        "hr.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u5rOmIaUvAt"
      },
      "source": [
        "#Summary for each variable\n",
        "hr.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp-8Ct6CUvJA"
      },
      "source": [
        "#To get the unique values for department\n",
        "hr['department'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q91ZUB5qVEzx"
      },
      "source": [
        "\n",
        "#Combine \"technical\",\"support\" and \"IT\" into one department\n",
        "hr['department']=np.where(hr['department'] =='support', 'technical', hr['department']) #DATAX NEED TO GIVE ENTER NAME OF DEPARTMENTS YOU WANT TO SEGREGRATE\n",
        "hr['department']=np.where(hr['department'] =='IT', 'technical', hr['department'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNCQumrcVE3Q"
      },
      "source": [
        "\n",
        "#Print the updated values of departments\n",
        "print(hr['department'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuXw8xcgVE6m"
      },
      "source": [
        "\n",
        "hr['left'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQlLhIEkVE-y"
      },
      "source": [
        "hr.groupby('left').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhkPuSEqVa6W"
      },
      "source": [
        "hr.groupby('department').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0QHNXRiVa9Q"
      },
      "source": [
        "\n",
        "hr.groupby('salary').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ9KPideVbAI"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "#Bar chart for department employee work for and the frequency of turnover\n",
        "pd.crosstab(hr.department,hr.left).plot(kind='bar')\n",
        "plt.title('Turnover Frequency for Department')\n",
        "plt.xlabel('Department')\n",
        "plt.ylabel('Frequency of Turnover')\n",
        "plt.savefig('department_bar_chart')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn0LWiD-VbDj"
      },
      "source": [
        "#Bar chart for employee salary level and the frequency of turnover\n",
        "table=pd.crosstab(hr.salary, hr.left)\n",
        "table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
        "plt.title('Stacked Bar Chart of Salary Level vs Turnover')\n",
        "plt.xlabel('Salary Level')\n",
        "plt.ylabel('Proportion of Employees')\n",
        "plt.savefig('salary_bar_chart')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0k9ba3fVbLv"
      },
      "source": [
        "#Proportion of employees left by department\n",
        "pd.crosstab(hr.department, hr.left)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJEsgmb6VFCI"
      },
      "source": [
        "#Histogram of numeric variables\n",
        "num_bins = 10\n",
        "\n",
        "hr.hist(bins=num_bins, figsize=(20,15))\n",
        "plt.savefig(\"hr_histogram_plots\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHtB6TMpV5IJ"
      },
      "source": [
        "\n",
        "hr.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dbXb27BV5Lg"
      },
      "source": [
        "cat_vars=['department','salary']\n",
        "for var in cat_vars:\n",
        "    cat_list='var'+'_'+var\n",
        "    cat_list = pd.get_dummies(hr[var], prefix=var)\n",
        "    hr1=hr.join(cat_list)\n",
        "    hr=hr1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiL7rWJqV5Of"
      },
      "source": [
        "\n",
        "hr.drop(hr.columns[[8, 9]], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7mza9h-V5S6"
      },
      "source": [
        "hr.columns.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OryBJDoyV5WU"
      },
      "source": [
        "hr_vars=hr.columns.values.tolist()\n",
        "y=['left']\n",
        "X=[i for i in hr_vars if i not in y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEgj_Rh0WHYo"
      },
      "source": [
        "\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDR9AlV3WHbq"
      },
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#Recursive Feature Elimination (RFE)\n",
        "model = LogisticRegression()\n",
        "\n",
        "rfe = RFE(model, 10)\n",
        "rfe = rfe.fit(hr[X], hr[y])\n",
        "print(rfe.support_)\n",
        "print(rfe.ranking_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duqmyf8NWHey"
      },
      "source": [
        "\n",
        "cols=['satisfaction_level', 'last_evaluation_rating', 'time_spend_company', 'Work_accident', 'promotion_last_5years', \n",
        "      'department_RandD', 'department_hr', 'department_management', 'salary_high', 'salary_low'] \n",
        "X=hr[cols]\n",
        "y=hr['left']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO5Qa2uvWHhy"
      },
      "source": [
        "#Logistic Regression\n",
        "#Split data into training and test samples\n",
        "from sklearn.cross_validation import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XERl7Fb5WHlB"
      },
      "source": [
        "#Logistic Regression Classifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcd_8LP-WHog"
      },
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Logistic regression accuracy: {:.3f}'.format(accuracy_score(y_test, logreg.predict(X_test))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEgxa0LVWig1"
      },
      "source": [
        "\n",
        "#Random Forest Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v-7ER1AWiki"
      },
      "source": [
        "print('Random Forest Accuracy: {:.3f}'.format(accuracy_score(y_test, rf.predict(X_test))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUggwAivWinp"
      },
      "source": [
        "#SVM Classifier\n",
        "from sklearn.svm import SVC\n",
        "svc = SVC()\n",
        "svc.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edRCZ_1KWz0o"
      },
      "source": [
        "print('Support vector machine accuracy: {:.3f}'.format(accuracy_score(y_test, svc.predict(X_test))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfFV4Tx4Wz4v"
      },
      "source": [
        "\n",
        "#For Random Forest\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import cross_val_score\n",
        "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
        "modelCV = RandomForestClassifier()\n",
        "scoring = 'accuracy'\n",
        "results = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "print(\"10-fold cross validation average accuracy for Random Forest Classifier: %.3f\" % (results.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCek2OfzWz74"
      },
      "source": [
        "#For SVM\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import cross_val_score\n",
        "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
        "modelCV = SVC()\n",
        "scoring = 'accuracy'\n",
        "results = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "print(\"10-fold cross validation average accuracy for SVM Classifier: %.3f\" % (results.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UGOuFJoW0AF"
      },
      "source": [
        "\n",
        "#Precison Recall Scores for Random Forest\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, rf.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ1VjVAoW0Dc"
      },
      "source": [
        "#Confusion Matrix for Random Forest\n",
        "y_pred = rf.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "forest_cm = metrics.confusion_matrix(y_pred, y_test, [1,0])\n",
        "sns.heatmap(forest_cm, annot=True, fmt='.2f',xticklabels = [\"Left\", \"Stayed\"] , yticklabels = [\"Left\", \"Stayed\"] )\n",
        "plt.ylabel('True class')\n",
        "plt.xlabel('Predicted class')\n",
        "plt.title('Random Forest')\n",
        "plt.savefig('random_forest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ68Cb7gXGEz"
      },
      "source": [
        "#PRScores for Logistic Regression\n",
        "print(classification_report(y_test, logreg.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqW7pTbFXGQz"
      },
      "source": [
        "#Confusion Matrix for Logistic Regression\n",
        "logreg_y_pred = logreg.predict(X_test)\n",
        "logreg_cm = metrics.confusion_matrix(logreg_y_pred, y_test, [1,0])\n",
        "sns.heatmap(logreg_cm, annot=True, fmt='.2f',xticklabels = [\"Left\", \"Stayed\"] , yticklabels = [\"Left\", \"Stayed\"] )\n",
        "plt.ylabel('True class')\n",
        "plt.xlabel('Predicted class')\n",
        "plt.title('Logistic Regression')\n",
        "plt.savefig('logistic_regression')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgLj0DZKXGUi"
      },
      "source": [
        "#PR scores for SVM\n",
        "print(classification_report(y_test, svc.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AoGvQbQXGYj"
      },
      "source": [
        "\n",
        "#Confusion Matrix for SVM\n",
        "svc_y_pred = svc.predict(X_test)\n",
        "svc_cm = metrics.confusion_matrix(svc_y_pred, y_test, [1,0])\n",
        "sns.heatmap(svc_cm, annot=True, fmt='.2f',xticklabels = [\"Left\", \"Stayed\"] , yticklabels = [\"Left\", \"Stayed\"] )\n",
        "plt.ylabel('True class')\n",
        "plt.xlabel('Predicted class')\n",
        "plt.title('Support Vector Machine')\n",
        "plt.savefig('support_vector_machine')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW1rZvuIXGb5"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "#ROC for logistic regression\n",
        "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
        "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
        "\n",
        "#ROC for Random Forrest\n",
        "rf_roc_auc = roc_auc_score(y_test, rf.predict(X_test))\n",
        "rf_fpr, rf_tpr, rf_thresholds = roc_curve(y_test, rf.predict_proba(X_test)[:,1])\n",
        "\n",
        "#ROC Curve for Random Forest & Logistic Regression\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
        "plt.plot(rf_fpr, rf_tpr, label='Random Forest (area = %0.2f)' % rf_roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('ROC')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFqppyJXWirB"
      },
      "source": [
        "feature_labels = np.array(['satisfaction_level', 'last_evaluation', 'time_spend_company', 'Work_accident', 'promotion_last_5years', \n",
        "      'department_RandD', 'department_hr', 'department_management', 'salary_high', 'salary_low'])\n",
        "importance = rf.feature_importances_\n",
        "feature_indexes_by_importance = importance.argsort()\n",
        "for index in feature_indexes_by_importance:\n",
        "    print('{}-{:.2f}%'.format(feature_labels[index], (importance[index] *100.0)))\n",
        "    analysis_result += ('{}-{:.2f}%'.format(feature_labels[index], (importance[index] *100.0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyztLn49Xd0e"
      },
      "source": [
        "file = open(\"variable_importance.txt\",\"w+\") #DATAX NEED TO ADD COPY THE FILE NAME GIVEN\n",
        "file.write(analysis_result)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_ungSlpXd60"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c73XHtrGXd-Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}